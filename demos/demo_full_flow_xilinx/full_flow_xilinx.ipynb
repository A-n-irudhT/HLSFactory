{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xilinx Full Flow Demo (Xilinx)\n",
    "\n",
    "This is an interactive notebook version fo the `full_flow_xilinx.py` demo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLSFactory Imports\n",
    "\n",
    "Below, we import all the necessary items from the HLSFactory library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hlsfactory.datasets_builtin import (\n",
    "    datasets_builder,\n",
    ")\n",
    "from hlsfactory.flow_vitis import (\n",
    "    VitisHLSImplFlow,\n",
    "    VitisHLSImplReportFlow,\n",
    "    VitisHLSSynthFlow,\n",
    ")\n",
    "from hlsfactory.framework import (\n",
    "    count_total_designs_in_dataset_collection,\n",
    ")\n",
    "from hlsfactory.opt_dsl_frontend import OptDSLFrontend\n",
    "from hlsfactory.utils import (\n",
    "    DirSource,\n",
    "    ToolPathsSource,\n",
    "    get_tool_paths,\n",
    "    get_work_dir,\n",
    "    remove_and_make_new_dir_if_exists,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we setup the work directory (where everything will run and be stored on disk).\n",
    "\n",
    "The call to `get_work_dir` uses an `.env` file looks for a variable/key called `HLSFACTORY_WORK_DIR`.\n",
    "\n",
    "Then we create a sub-directory in this work directory for this specific demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR_TOP = get_work_dir(dir_source=DirSource.ENVFILE)\n",
    "WORK_DIR = WORK_DIR_TOP / \"demo_full_flow_xilinx\"\n",
    "remove_and_make_new_dir_if_exists(WORK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we setup the number of parallelism to use for our flows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 32\n",
    "CPU_AFFINITY = list(range(N_JOBS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also setup the paths to the Xilinx tools.\n",
    "\n",
    "The call to `get_tool_paths` uses an `.env` file and for variables/keys called `HLSFACTORY_VITIS_HLS_PATH` and `HLSFACTORY_VIVADO_PATH`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VITIS_HLS_PATH, VIVADO_PATH = get_tool_paths(tool_paths_source=ToolPathsSource.ENVFILE)\n",
    "VIVADO_BIN = VIVADO_PATH / \"bin\" / \"vivado\"\n",
    "VITIS_HLS_BIN = VITIS_HLS_PATH / \"bin\" / \"vitis_hls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we setup some datasets supported by the Xilinx flows.\n",
    "\n",
    "We use the built-in `polybench`, `machsuite`, and `chstone` datasets.\n",
    "\n",
    "The call to `datasets_builder` copies the built-in datasets, the work directory, renames them according to the user provided labels, and returns a `DatasetCollection` (dict) object of `DesignDatasets` objects, one for each dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets_builder(\n",
    "    WORK_DIR,\n",
    "    [\n",
    "        \"polybench\",\n",
    "        \"machsuite\",\n",
    "        \"chstone\",\n",
    "    ],\n",
    "    dataset_labels=[\n",
    "        \"polybench_xilinx\",\n",
    "        \"machsuite_xilinx\",\n",
    "        \"chstone_xilinx\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commented code below show an alternative way to setup the the datasets the same way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dataset_polybench_xilinx = dataset_polybench_builder(\"polybench_xilinx\", WORK_DIR)\n",
    "dataset_machsuite_xilinx = dataset_machsuite_builder(\"machsuite_xilinx\", WORK_DIR)\n",
    "dataset_chstone_xilinx = dataset_chstone_builder(\"chstone_xilinx\", WORK_DIR)\n",
    "\n",
    "datasets: DesignDatasetCollection = {\n",
    "    \"polybench_xilinx\": dataset_polybench_xilinx,\n",
    "    \"machsuite_xilinx\": dataset_machsuite_xilinx,\n",
    "    \"chstone_xilinx\": dataset_chstone_xilinx,\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the total number of designs in the dataset collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Designs: 29\n"
     ]
    }
   ],
   "source": [
    "total_count = count_total_designs_in_dataset_collection(datasets)\n",
    "print(f\"Total Designs: {total_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontend for Design Space Elaboration\n",
    "\n",
    "The selected datasets can be utilized within the Optimization DSL (Opt. DSL) Frontend to generate a variety of designs, each applying different combinations of optimization directives.\n",
    "\n",
    "To achieve this, create an instance of `OptDSLFrontend` and invoke the `execute_*` method to operate this frontend. This process will generate a new dataset collection comprising various design datasets that include the sampled designs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we specify the number of randomly sampled designs with varying optimization directive combinations. Additionally, a seed can be set for this sampling to ensure reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RANDOM_SAMPLES = 12\n",
    "RANDOM_SAMPLE_SEED = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the `OptDSLFrontend` object and call the `execute_multiple_design_datasets_fine_grained_parallel` run the frontend for all the designs for all the datasets in parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 17895.37it/s]\n"
     ]
    }
   ],
   "source": [
    "opt_dsl_frontend = OptDSLFrontend(\n",
    "    WORK_DIR,\n",
    "    random_sample=True,\n",
    "    random_sample_num=N_RANDOM_SAMPLES,\n",
    "    random_sample_seed=RANDOM_SAMPLE_SEED,\n",
    "    log_execution_time=True,\n",
    ")\n",
    "datasets_post_frontend = (\n",
    "    opt_dsl_frontend.execute_multiple_design_datasets_fine_grained_parallel(\n",
    "        datasets,\n",
    "        True,\n",
    "        lambda x: f\"{x}__post_frontend\",\n",
    "        n_jobs=N_JOBS,\n",
    "        cpu_affinity=CPU_AFFINITY,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of designs in the dataset collection post-frontend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Designs post-frontend: 348\n"
     ]
    }
   ],
   "source": [
    "total_count_post_frontend = count_total_designs_in_dataset_collection(\n",
    "    datasets_post_frontend,\n",
    ")\n",
    "print(f\"Total Designs post-frontend: {total_count_post_frontend}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS Synthesis and Implementation Flows\n",
    "\n",
    "Now, we take all the designs, execute HLS synthesis on each, and subsequently run the normal FPGA synthesis and implementation for each design.\n",
    "\n",
    "As before, create instances of `VitisHLSSynthFlow` and `VitisHLSImplFlow`, and then invoke their `execute_*` methods to operate the flows.\n",
    "\n",
    "It is important to note that the `VitisHLSSynthFlow` manages both the HLS synthesis and the automatic extraction of data from the synthesis reports within the same flow, eliminating the need for an additional step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the HLS synth. and impl. flow steps, the user can set the timeout for each step.\n",
    "\n",
    "If a flow step takes longer than the timeout, then that design flow is terminated and that design is not collected to output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEOUT_HLS_SYNTH = 60.0 * 8  # 8 minutes\n",
    "TIMEOUT_HLS_IMPL = 60.0 * 30  # 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a worst case estimation of the total build time based on the number of designs and the timeout for each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time_estimation = (\n",
    "    total_count_post_frontend * (TIMEOUT_HLS_SYNTH + TIMEOUT_HLS_IMPL) / N_JOBS\n",
    ")\n",
    "print(\n",
    "    f\"Estimated worst-case build time:\\n{total_time_estimation} seconds\\n{total_time_estimation / 60} minutes\\n{total_time_estimation / 3600} hours\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we setup and run both flows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolflow_vitis_hls_synth = VitisHLSSynthFlow(\n",
    "    vitis_hls_bin=str(VITIS_HLS_BIN),\n",
    "    env_var_xilinx_hls=str(VITIS_HLS_PATH),\n",
    "    env_var_xilinx_vivado=str(VIVADO_PATH),\n",
    ")\n",
    "datasets_post_hls_synth = (\n",
    "    toolflow_vitis_hls_synth.execute_multiple_design_datasets_fine_grained_parallel(\n",
    "        datasets_post_frontend,\n",
    "        False,\n",
    "        n_jobs=N_JOBS,\n",
    "        cpu_affinity=CPU_AFFINITY,\n",
    "        timeout=TIMEOUT_HLS_SYNTH,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolflow_vitis_hls_implementation = VitisHLSImplFlow(\n",
    "    vitis_hls_bin=str(VITIS_HLS_BIN),\n",
    "    env_var_xilinx_hls=str(VITIS_HLS_PATH),\n",
    "    env_var_xilinx_vivado=str(VIVADO_PATH),\n",
    ")\n",
    "datasets_post_hls_implementation = toolflow_vitis_hls_implementation.execute_multiple_design_datasets_fine_grained_parallel(\n",
    "    datasets_post_hls_synth,\n",
    "    False,\n",
    "    n_jobs=N_JOBS,\n",
    "    cpu_affinity=CPU_AFFINITY,\n",
    "    timeout=TIMEOUT_HLS_IMPL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vivado Reporting Flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also run one last flow to extract data from the Vivado reports including power, timing, and resource utilization data.\n",
    "\n",
    "Unlike the `VitisHLSSynthFlow`, the `VitisHLSImplFlow` does not automatically extract data from the reports.\n",
    "In the future, we might refactor the impl. flow to also run the report extraction or we refactor the HLS synth. flow to break out the HLS report extraction into a separate step; ideally we would do this to maintain API consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolflow_vitis_hls_impl_report = VitisHLSImplReportFlow(\n",
    "    vitis_hls_bin=str(VITIS_HLS_BIN),\n",
    "    vivado_bin=str(VIVADO_BIN),\n",
    "    env_var_xilinx_hls=str(VITIS_HLS_PATH),\n",
    "    env_var_xilinx_vivado=str(VIVADO_PATH),\n",
    ")\n",
    "toolflow_vitis_hls_impl_report.execute_multiple_design_datasets_fine_grained_parallel(\n",
    "    datasets_post_hls_implementation,\n",
    "    False,\n",
    "    n_jobs=N_JOBS,\n",
    "    cpu_affinity=CPU_AFFINITY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Conclusion and Next Steps\n",
    "\n",
    "All the output data from HLS synthesis and FPGA implementation is located in the `WORK_DIR`.\n",
    "\n",
    "Our flows have extracted the relevant data into data files alongside the design sources and project files.\n",
    "\n",
    "This data can be aggregated and further process and analyzed, also using HLSFactory, or by the user, for specific research or development needs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
